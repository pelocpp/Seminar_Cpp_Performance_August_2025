C++ Performance Optimierung
=============================

Peter Loos

peter.loos@gmx.de
-----------------

=============================

TbD:

Algos ...
Profiling ...


Warum KÖNNEN / Sind Algorithmen besser ..............

=============================

2 Ideen zum Nachdenken:
-----------------------

a) Allokator ==> Fixed-Block Allokatoren

   Manager ===>  STL  //  new / delete 


b) Object Pool

   Ähnlichkeit: Alle Objekte in einem Pool haben diesselbe Größe.
                und auch desselben Typs !!!

   Wiederverwendet.

=============================


Unterlagen:

https://github.com/pelocpp

https://github.com/pelocpp/cpp_clean_performant_secure/blob/master/Clean_Performant_Code/Performance_Optimization/Readme_Performance_Optimization.md

=============================

std::initializer_list
----------------------

Misunderstanding:

Memberwise Initializer List



std::initializer_list:    Stack

std::vector:              Heap

Stack ist performanter ===> bin schneller.

Go for std::initializer_list // Parameter-Übergabe.

=============================

std::string / SSO
-----------------

Wo liegen die Zeichen eines std::string-Objekts ????


Die Nutzdaten, also die Zeichen selbst, liegen auf dem Heap !

Ausnahme:

Optimierungstechnik:

Kleine Zeichenketten ????

Hängt vom Compiler / Bibliothek ab:

===============================

Ausprobieren:

Online C++ Compiler

https://wandbox.org/

===============================

std::string: 40 bytes ===> geht das auch mit weniger ???

Frage:

"Dies ist eine Zeichenkette"

Wo liegt in der Ausführung diese Zeichenkette ????

String Literal: Von welchem Typ ist ein String Literal

const char* s = "Dies ist eine Zeichenkette";

Bemerkung:

In C // String Literal:

char* s = "Dies ist eine Zeichenkette";
s[0] = '?';  // C++: Error

Heap: Nicht auf dem Heap.

Code Segement: Jepp.
Global Data Segment:  2 Arten : Initialisiert (.data)
                      und nicht initialisiert (.bss)


C++:

const char* s = "Dies ist eine Zeichenkette";

std::string s = "Dies ist eine Zeichenkette";   // Heap

std::string_view s = "Dies ist eine Zeichenkette"; 
   // da, const char* liegt

Performanz:

Warum sollen konstante Zeichenketten auf dem Heap abgelegt werden ???
Da gibt es keinen Grund dafür

==> std::string_view:

Wie sieht std::string_view INTERN aus ???

a) const char*
b) Länge


Wie sehen einzelne String-Funktionen
im Vergleich aus:

SubString
Tail - letzten n Zeichen
Head - ersten n Zeichen

Go for string_view bei konstanten Zeichenketten

=======================================

Call-by-Value vs. Call-by-Referenz:

Call-by-Value:
    int m = n;
00007FF6F00BCB2F  mov         eax,dword ptr [n]  
00007FF6F00BCB35  mov         dword ptr [m],eax  

Call-by-Ref:
    int m = n;
00007FF6F00BCB70  mov         rax,qword ptr [n]  
00007FF6F00BCB77  mov         eax,dword ptr [rax]  
00007FF6F00BCB79  mov         dword ptr [m],eax  


Call-by-Ref ist ein INDIREKTER Zugriff:
   das würde ich bei elem. Variablen 
   eher nicht machen !

Bei Objekten ist es genau anders herum
Da kostet das Kopieren Laufzeit.
Call-by-Ref ist hier besser 

==============================================

Schlagwort:

Copy/Move Elision

Elision: to elide ===> weglassen, auslassen.

"Man kommt damit nicht direkt in Kontakt"

https://github.com/pelocpp/cpp_modern/blob/master/GeneralSnippets/CopyMoveElision/CopyMoveElision.md

Frage:

static std::unique_ptr<int> loadUniquePointer()
{
    std::unique_ptr<int> emtpy;

    std::unique_ptr<int> ptr{ std::make_unique<int>(100) };
    
    return std::move (ptr);  // gut / schlecht ????
}


return std::move (ptr);:   NIEMALS: 

Der Compiler kann das selbst am besten:
Ein Objekt zurückgeben -- hier nicht hinlangen !!!!

==============================================

constexpr 
---------

Kleine Runde:

IIFE - Immediately Invoked Functional Expression

Verbesserung:  Makros a la C

==============================================

Lamdbas:

Man will Lambdas häufig einen Namen geben.

== inline-Code

== Zugriff auf Variablen aus dem umgebenden Scope

=====================================================
constexpr


Ergibt constexpr Sinn bei std::vector oder std::string ???

==> Haben ihre Daten auf dem Heap !!!

Neues Konzept:

Transiente Allokation
---------------------

New ist in im constexpr Kontext erlaubt,
wenn im gleichen Scope das delete vorhanden ist.

=================================================

static void tueWas()
{
    int n = 1;
    int m = 2;
    int offset = 10;

    auto l = [&n, m](int n) {
        return n + offset;
    };

    auto result = l(20);
}

Capture Klausel:

=    =>  KOPIE
&    =>  REFERENZ

Unbekannter // C++ 14:

Verschieben // Move ????????????

Geht auch.

================================================

Verschieben: Ist ja besser als Kopieren.

Wenn Parameter von Funktion zu Funkion
durchgereicht werden, könnte es passieren (unvorsichtig),
dass eine Kopie reinrutscht.

===> Perfekt Forwarding.

https://github.com/pelocpp/cpp_modern/blob/master/Readme.md

Klassische Typ:  &

Neuer Typ        &&

Wer ist T&&, wenn T ein Template Parameter ist:

Universal Referenz.



Referenz-Typ:

Wozu // für welche Objekte:

Für anonyme Objekte / ohne Namen.

LValue ===> LValue 

RValue ===> RValue 

Performanz:  VERSCHIEBEN  // Nicht kopieren.

Kochrezept:
-----------

A) Funktionstemplate: Muss T&& universelle Referenzen.

B) Unterlagert weiterreichen: std::forward<>

====================================================

„Folding”-Ausdrücke

Beispiel:

1 + 2 + 3 + 4 + 5 + 6 + 7 + 8

A) arithm. Ausdrücke

b) Es wird nur EIN Operator verwendet.

Hochperformante Umsetzungen/ Ausführungen:

    int result = addierer(1, 2, 3, 4, 5, 6, 7, 8);

A) Wie bekomme ich die Parameter an die Funktion übergeben

B) Syntax des Folding-Ausdrucks

https://github.com/pelocpp/cpp_modern/blob/master/GeneralSnippets/Folding/Folding.md

===========

C++: 

i)  Core als Sprache
ii) Generische Programmierung: Templates


=====================================================

Funktionale Programmierstil:

Pro:  Keine Instanzvariablen.

Umgekehrt:  Um in C++ optimieren zu können:

====> const 

=================================================================

Speicher unter der Lupe:

Debug-Mode:
Zwischen zwei Variablen werden ca. 30 Füllbytes eingefügt.

Mit dem Muster CC = 1100 1100 

=========================================================

CPU-Cache // Cache Line:

Was hat das mit C++ zu tun ???????????????????

Wenn es machbar ist:

"Hüpfen" im Speicher soweit es geht vermeiden :)

Beispiel:

Matrix:  Okay, im Debug - Modus kann  man das beobachten.

Im Release-Modus nicht.

============================================================

False Sharing


============================================================

Zusammenfassung:

a) Cache Line: Nicht springen

   ==> Cache Miss

b) DIESELBE Cache-Line von mehrere Threads verwendet

   ==> Cache Thrash

============================================================

Speicher:

Wo kommt der Speicher her ???

Heap:

   Zugang indirekt // new //  std::malloc

   Hier kümmert sich die Bibliothek darum.

Globalen Datensegment:  

   Direkter Zugang:

   char* buffer [10000];

   AUSRICHTUNG // Alignment ....

Frage:

Generell gilt:
Die größten Datenelemente sollten am Anfang
und die kleinsten am Ende platziert werden.
Auf diese Weise lässt sich der durch das Padding
verursachte Speicheraufwand minimieren.

struct Document d;

int* p = & d.m_id;



class Document_V2
{
    double     m_rank;
    int        m_id;
    bool       m_isCached;
};

Konstruktor:


class Document_V2
{
    Document_V2() 
    : m_rank{ 1.0},m_id{}, m_isCached{false} , m_rank2{m_rank}
    {}

    double     m_rank;
    int        m_id;
    bool       m_isCached;
    double     m_rank2;
};

================================================

Laufzeiten

Benchmarking:

Mikro-Benchmarking
------------------

== Google Test



Makro-Benchmarking
------------------

// =============================================

A) Da kann regulärer C++ Code rein (Copy/Paste)

B) #include's:

   i)  Erst mal nicht.
   ii) Wenn sie fehlen, ergänzen (<string_view>)

C) Eine Funktion, die gestestet werden soll:

   Hat einen speziellen Parameter:

   benchmark::State& state

D) Dieser Parameter wird verwendet:

   
   // Range-based For-Loop
   for (auto _ : state) {

E) Nebenbemerkung: Was ist _ ???

   Wie ist ein Bezeichner definiert:
   A..Z, a..z, _, 0..9

   Was ist ein sehr kurzer Bezeichner:
   n
   _


F) Alles INNERHALB dieser Range-based For-Loop
   wird gemessen.

G) Eine Funktion, deren Zeit gemessen werden soll,
   muss REGISTRIERT werden:

// Register the function as a benchmark
BENCHMARK(StringCreation);

=============================================================

Issue:  Hmm, der zu testende Code wird "in erwarteter"
        Weise optimiert.



Abhilfe:

a)  // Make sure the variable is not optimized away by compiler
    benchmark::DoNotOptimize(created_string);

b)  Gebrauch von volatile.

Ist kontraproduktiv.


=============================================================

Beispiel:

static int malZwei(int n) {
    return 2 * n;
}

static void StringCreation(benchmark::State& state) {
  // Code inside this loop is measured repeatedly
  for (auto _ : state) {
    std::string created_string("hello");
    // Make sure the variable is not optimized away by compiler
    benchmark::DoNotOptimize(created_string);
  }
}

static void StringCopy(benchmark::State& state) {
  // Code before the loop is not measured
  std::string x = "hello";
  for (auto _ : state) {
    std::string copy(x);
  }
}

BENCHMARK(StringCopy);
BENCHMARK(StringCreation);

===================================================

Wie kann man ein Lambda-Objekt in
einem Programm namentlich ansprechen:

a) auto l = [] () {};

b) 

auto product = [] (int a, int b) -> int {
    return a * b;
};

Bemerkung: Manchmal MUSS man std::function verwenden,
wenn man Lambdas abspeichern möchte:
Instanzvariablen von Objekten.


Hinweis:

Funktionszeiger:

 int (*fp) (int, int);

std::function< int (int, int) > f;

Hilfestellung:

Cpp Insights:

https://cppinsights.io/

Abbildung:  Quellcode Modern C++ ==>  Quellcode Classic C++

===================================================
===================================================

Performanz

===========> Speicherverwaltung:

Bibliothek: new / delete / malloc / free

Speicherverwaltung:

Die Anforderungen Blöcke unterschiedlicher Größe.

Ansätze:

Was ist mit Blöcken gleicher größe ???

==> Fixed-Size Block Allokatoren.

Variable Ansatz: Standard-Pool (new/delete) rausnimmt.

Wie ???

C++: Hat nahezu alles offen gelegt:

Speicher zu verwalten:

STL

std::vector<int>

std::vector<int, Allocator>

==> Welche Optionen bietet C++ / STL,
um sich in den Zugang zum Speicher dazwischenzuschalten.

==> Können wir das ausnutzen ???

Skuriles Thema:

Laundry // Zeiger "waschen" 

Objekten / Klassen:   Kopien ...

Klassen mit ...

== Referenzen
== const Elementen

Hintergründe: std::launder

================================================================

Performanz Optimierung:

Gebrauch des Schlüsselworts noexcept:

noexcept ==> Kein Stack-Unwinding Code wird erzeugt.

Wenn's kracht: terminate();

Wann ist es denn gefahrlos:

  == Methoden, die oder weniger nur aus Wertzuweisungen bestehen.
  == getter


================================================================

+		dummy	0x0000000000000000 <NULL>	std::_Container_proxy *

std::_Container_proxy 

================================================================

Wie könnte man einen Allokator selbst schreiben:

A) Für Fixed-Size Blöcke ist das nicht so schwer ....

Was ist eine "Arena":   Ein großer Block von Speicher.



==========================================================================

+		dummy	0x0000000000000000 <NULL>	

std::_Container_proxy *

std::_Flist_node<double,void *> *


Angepasst  // muss überprüft werden !!!

==> Optimierungspotential: 

Bei Blöcken derselben Größe.

===============================================================

Memory Manager:
---------------

STL: Als / Hinter einem Allokator 
     in bestimmten STL-Klassen einbauen.

     Geht nicht mit jeder STL-Klasse:


    std::vector<> mit Anforderungen
    unterschiedlicher Größe ist da nicht geeignet.

An Klassen: new / delete: Spezialisieren.


===========================

Kann man Zeiger // new // Arena auf 
Plausibilität überprüfen ???

Schwache Option:

static const size_t ArenaSize = 8'000;    // needed for new / delete examples
static alignas(std::max_align_t) char arena[ArenaSize]{};


if (ptr >= arena && ptr <= arena + ArenaSize)  ...

==> new bzgl. des Systems.


Freigabe:

if (ptr >= arena && ptr <= arena + ArenaSize)  ...
   Freigabe mit der Arena
else
   delete ptr;

Warum ist klassen-spezifisches new / delete incl. Arena
sehr viel schneller ????

Was ist das generelle Problem:

Speicherverwaltung: 

Blöcke unterschiedlicher Größe:

==============================================================

new

delete

std::malloc

std:free

A) Blöcke:  4k

Arena:

Zweite Arena nachgeladen.

GlobalAlloc // LocalAlloc
-----------


==============================================================

Mikro-Benchmarking

Makro-Benchmarking

==============================================================

Profiling:

1234 3232

==============================================================

2 Ideen zum Nachdenken:
-----------------------

a) Allokator ==> Fixed-Block Allokatoren
   -------------------------------------

   Fixed Block Allocator

   Manager ===>  STL  //  std::list, std::forward_list, ..
   Manager ===>  new / delete 


b) Object Pool
--------------

   Ähnlichkeit: Alle Objekte in einem Pool haben diesselbe Größe.
                und auch desselben Typs !!!

   Der Pool kann eine "beliebige Anzahl" von Objekten 
   halten: 

   Diese werden nach Gebrauch nicht an das unterlagerte
   OS zurückgegen (passivem Zustand).


   ===================================================

   C#:   Klasse Color  // Farben Farb-Objekte

   Color red  {  FF, 0, 0 };

   Color c = Color.FromRGB ( FF, 0, 0);

===================================================

Was ist der Vorteil eines solchen Pools:

new / delete

new (params)      => Speicher holen

acquire (params)  => vorhandenen Speicher zuweisen

Frage // Antwort:

Man kann das "punktuell" sehen.

ABER: 

Es wurden VIELE unterschiedliche Anforderungen
an das Mem. Management bereits gestellt.

Sitution: Speicher: Defragmentierung // Zersplitterung.

Hat ein new IMMER DIESELBE Laufzeit ???
Sitution im vorh. Memory die Laufzeit sich ändern ???

===================================================

Go for Algorithms:
------------------

std::iota  // Algorithmen

Motivieren ...  

===================================================

Coroutines:
-----------

"Der neueste Schrei in C++"

Coroutines haben mit Multithreading
keinen direkten Bezug.

https://github.com/pelocpp/cpp_23/blob/master/Programs/01_Coroutines/Readme.md


01: std::vector<int> getNumbers(int begin, int end)
02: {
03:     std::vector<int> numbers;
04: 
05:     for (int i = begin; i <= end; ++i) {
06:         numbers.push_back(i);
07:     }
08: 
09:     return numbers;
10: }

Stilistik:  Gierig // Greedy // Eager Algorithmus

“lazy”-Strategie

Kontrollfluss zwischen einem Produzenten (Coroutine) und einem Konsumenten (Anwendung).

Beispiele:

Socket:   Warten auf Verbinding // eine Verbindung bedienen

Parsen // Übersetzen:

== Eingabe zerleben // getNextToken

== Syntax überprüfen ... ein Token nach dem anderen

== Produzenten // Konsumenten Szenario

======================================================

Wehrmutstropfen:

Ich muss ein Coroutinen-Interface
implementieren // bereitstellen.

Kontrakt:

a) Typ 'promise_type' muss vorhanden sein.

b) Ein std::coroutine_handle<promise_type> muss vorhanden sein.

   == destroy // stackless // Heap // Ende: destroy

c) Ein bestimmtes Interface bedienen:

   resume:

   Kann an resume des unterlagerten Promise-Objekts
   weiter geleitet werden.


Zur Klasse 'promise_type':

== get_return_object

   Liefert ein Interface-Objekt zurück.

   Promise Typ ist als Absender enthalten.





Zum Warten:

co_await std::suspend_always{};    // Immer warten

co_await std::suspend_never{};    // Nie warten


Hin- und her:

2 Beteiligte

Beide wollen möglicht unabhängig voneinander arbeiten:

==> resume 

<== yield

==============================================

Performanz:

STL: Überarbeitung.

===> Bibliothk  std::ranges.

https://github.com/pelocpp/Seminar_Cpp_Performance_August_2025/blob/master/Clean_Performant_Code/Ranges/Readme_Ranges.md

Wie arbeiten Views - im Gegensatz zur STL:

LAZY.

===========================================

struct NegativeNumber
{
    bool operator== (std::input_iterator auto iter) const {
        return *iter < 0;
    }
};

template <typename T>
    required std::is_same<T, std::input_iterator>
struct NegativeNumber
{
    bool operator== (T iter) const {
        return *iter < 0;
    }
};

=================================================

C++ Performance Optimierung:

Multi-Threading // Concurrency:
------------------------------------------


Unterlagen siehe

https://github.com/pelocpp/cpp_concurrency

C++ Werkzeugkasten: 

Grundlagen:   std::thread


Windows:  Beendet sich der Primärthread einer Anwendung,  
         dann werden alle Sekundärthreads ebenfalls beendet.


=================================================

== std::thread    // Klassen
== std::jthread

== std::async     // Funktion


Was ist ein Nachteil eines "herkömmlichen" Threads ???????????

Das ist ein Thread (OS), der nur EINMAL verwendet werden kann:

Beispiel:

WebService  // Socket-Server:

Jedem Incoming Request einen Client-spezifischen Thread:

CreateThread ist da KEINE Lösung.

Thread Pool: 

Steht std::async mit einem Thread Pool in Verbindung ??????????????????
























